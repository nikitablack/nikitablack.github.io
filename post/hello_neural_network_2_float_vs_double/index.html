<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"  lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1"/>


<title>Hello, Neural Network 1.5! Float vs Double. | Here should be the blog Title</title>



<link href="http://nikitablack.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Here should be the blog Title" />

<link rel="stylesheet" href="/css/style.css"/>
<link rel="stylesheet" href="/css/css_lightbox.css"><link rel='stylesheet' href='http://nikitablack.github.io/css/custom.css'><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<link rel="canonical" href="http://nikitablack.github.io/post/hello_neural_network_2_float_vs_double/">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>

<section class="section">
  <div class="container">
    <nav id="nav-main" class="nav">
      <div id="nav-name" class="nav-left">
        <a id="nav-anchor" class="nav-item" href="http://nikitablack.github.io/">
          <h1 id="nav-heading" class="title is-4">Here should be the blog Title</h1>
        </a>
      </div>
      <div class="nav-right">
        <nav id="nav-items" class="nav-item level is-mobile"><a class="level-item" aria-label="twitter" href='https://twitter.com/nikita_cherniy'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="github" href='https://github.com/nikitablack'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
    
  </svg></i>
            </span>
          </a><a class="level-item" aria-label="email" href='mailto:mynameisnikitablack@gmail.com'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
    
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
    <polyline points="22,6 12,13 2,6"/>
    
  </svg></i>
            </span>
          </a></nav>
      </div>
    </nav>

    <nav class="nav">
      

      
    </nav>

  </div>
  <script src="/js/navicon-shift.js"></script>
</section>
<section class="section">
  <div class="container">
    <div class="subtitle tags is-6 is-pulled-right">
      
    </div>
    <h2 class="subtitle is-6">August 17, 2025</h2>
    <h1 class="title">Hello, Neural Network 1.5! Float vs Double.</h1>
    
    <div class="content">
      <p>Last time I added a brief note about choosing <code>float</code> over <code>double</code>, where I said that <code>float</code> <em>is better</em> - because we&rsquo;ll work mostly with small numbers, so the precision is not an issue, and because GPUs prefer floats (at least, mass-consumer GPUs). Also, logic says that <code>float</code> should be faster - addition and subtraction should take the same amount of cycles, but memory throughput should be better with <code>float</code>, since more data can fit into a single cache line. I showed performance for single-precision floating point numbers - <em>&ldquo;When I came back, it had already finished with an average training time of 73071.55 ms.&quot;</em> But I did not measure the execution time when using <code>double</code>. In any case it should be slower, right? Right??</p>
<h2 id="float-vs-double">Float vs Double</h2>
<p>Not a problem, let&rsquo;s fill that gap. I reconfigure cmake with <code>cmake .. -DUSE_DOUBLE=ON</code>, rebuild the project, run it multiple times, averaging the result, and the execution time is&hellip; 56971.18 ms.</p>
<a href="#images%2f0.jpeg">
    <img src=images/0.jpeg class="thumbnail">
</a>
</br>
  

<a href="#_" class="lightbox" id="images/0.jpeg">
  <img src=images/0.jpeg>
</a>
<p>What. The. Hell? I was using standard C++, no fancy compiler options, and the code is quite simple. I tried to clean the build folder, rebuild, rerun. The results are the same. There&rsquo;s clearly something wrong when doing these dot products - it&rsquo;s the heaviest part. So I made a small test with two huuuge vectors and performed a dot-product on them. It didn&rsquo;t show anything - <code>floats</code> were faster.</p>
<p>But I can&rsquo;t leave without knowing what&rsquo;s going on. I didn&rsquo;t want to, but now I have to look at the assembly.</p>
<p>I&rsquo;ll focus on the <code>Layer::activate()</code> function. Namely, the line 14: <code>z += currNeuron.weights[j] * prevNeuron.value;</code>:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="display:block;width:100%;background-color:#3c3d38"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span></span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#a6e22e">[[nodiscard]]</span> <span style="color:#66d9ef">auto</span> Layer<span style="color:#f92672">::</span>activate(Layer <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;</span> prevLayer,  <span style="color:#75715e">//
</span><span style="color:#75715e"></span>                                   std<span style="color:#f92672">::</span>function<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">auto</span>(Float)<span style="color:#f92672">-&gt;</span>Float<span style="color:#f92672">&gt;</span> <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;</span> activationFunction  <span style="color:#75715e">//
</span><span style="color:#75715e"></span>                                   ) <span style="color:#66d9ef">noexcept</span> <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">bool</span> {
    <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> currNeuron : neurons) {
        Float z{currNeuron.bias};

        <span style="color:#66d9ef">for</span> (size_t j{<span style="color:#ae81ff">0</span>}; j <span style="color:#f92672">&lt;</span> prevLayer.neurons.size(); <span style="color:#f92672">++</span>j) {
            <span style="color:#66d9ef">if</span> (prevLayer.neurons.size() <span style="color:#f92672">&lt;</span> currNeuron.weights.size()) {
                <span style="color:#66d9ef">return</span> false;  <span style="color:#75715e">// Not enough weights for the neuron
</span><span style="color:#75715e"></span>            }

            <span style="color:#66d9ef">auto</span> <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;</span> prevNeuron{prevLayer.neurons[j]};

<span style="display:block;width:100%;background-color:#3c3d38">            z <span style="color:#f92672">+=</span> currNeuron.weights[j] <span style="color:#f92672">*</span> prevNeuron.value;
</span>        }

        currNeuron.value <span style="color:#f92672">=</span> activationFunction(z);
    }

    <span style="color:#66d9ef">return</span> true;
}
</code></pre></td></tr></table>
</div>
</div><p>Here&rsquo;s the assembly for the <code>double</code> version:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-asm" data-lang="asm"><span style="color:#a6e22e">movsd</span>    <span style="color:#66d9ef">xmm0</span>, <span style="color:#66d9ef">QWORD</span> <span style="color:#66d9ef">PTR</span> [<span style="color:#66d9ef">rdx</span>]      <span style="color:#75715e"># load prevLayer.neurons[j].value
</span><span style="color:#75715e"></span><span style="color:#66d9ef">movupd</span>   <span style="color:#66d9ef">xmm3</span>, <span style="color:#66d9ef">XMMWORD</span> <span style="color:#66d9ef">PTR</span> [<span style="color:#66d9ef">rax</span>]    <span style="color:#75715e"># load two contiguous weights
</span><span style="color:#75715e"></span><span style="color:#66d9ef">add</span>      <span style="color:#66d9ef">rax</span>,  <span style="color:#ae81ff">16</span>                   <span style="color:#75715e"># next 2 weights
</span><span style="color:#75715e"></span><span style="color:#66d9ef">add</span>      <span style="color:#66d9ef">rdx</span>,  <span style="color:#ae81ff">80</span>                   <span style="color:#75715e"># next neuron (stride = 80 bytes)
</span><span style="color:#75715e"></span><span style="color:#66d9ef">movhpd</span>   <span style="color:#66d9ef">xmm0</span>, <span style="color:#66d9ef">QWORD</span> <span style="color:#66d9ef">PTR</span> -<span style="color:#ae81ff">40</span>[<span style="color:#66d9ef">rdx</span>]   <span style="color:#75715e"># pack prevLayer.neurons[j-1].value into high lane
</span><span style="color:#75715e"></span><span style="color:#66d9ef">mulpd</span>    <span style="color:#66d9ef">xmm0</span>, <span style="color:#66d9ef">xmm3</span>                 <span style="color:#75715e"># dot product
</span><span style="color:#75715e"></span><span style="color:#66d9ef">addsd</span>    <span style="color:#66d9ef">xmm1</span>, <span style="color:#66d9ef">xmm0</span>
<span style="color:#a6e22e">unpckhpd</span> <span style="color:#66d9ef">xmm0</span>, <span style="color:#66d9ef">xmm0</span>
<span style="color:#a6e22e">addsd</span>    <span style="color:#66d9ef">xmm1</span>, <span style="color:#66d9ef">xmm0</span>
</code></pre></div><p>The first thing to note is the usage of <code>xmm</code> registers. My compiler (<code>gcc (Ubuntu 10.5.0-1ubuntu1~20.04) 10.5.0</code>) is smart enough to detect the pattern and vectorize the math. What&rsquo;s interesting is how data access is handled. <code>add rax, 16</code> - for weights, it just takes 2 consecutive doubles. That&rsquo;s perfectly fine, since the weights are stored in a contiguous vector (<code>std::vector&lt;Float&gt; Neuron::weights</code>).</p>
<p>The values, on the other hand, are stored one per neuron (<code>Float Neuron::value</code>), and neurons themselves are stored in a contiguous vector (<code>std::vector&lt;Neuron&gt; Layer::neurons</code>). Let&rsquo;s recall how the <code>Neuron</code> class is declared:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Neuron</span> {
<span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
    Float value{<span style="color:#ae81ff">0.0</span>};
    Float bias{<span style="color:#ae81ff">0.0</span>};
    std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Float<span style="color:#f92672">&gt;</span> weights{};
};
</code></pre></div><p>On my machine (and most likely on yours too), the size of a <code>std::vector</code> equals 24 bytes. The <code>double value</code> and <code>double bias</code> together take 16 bytes, which gives a total of 40 bytes per <code>Neuron</code>. This explains the number in the <code>movhpd xmm0, QWORD PTR -40[rdx]</code> line and the 80 in the <code>add rdx, 80</code> line - for 2 weights, the code reads 2 neurons and packs the data into a single 16-byte register. Then it performs multiplication on 2 doubles at once.</p>
<p>Now let&rsquo;s look at the generated assembly for the <code>float</code> version:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-asm" data-lang="asm"><span style="color:#a6e22e">movss</span>  <span style="color:#66d9ef">xmm0</span>, <span style="color:#66d9ef">DWORD</span> <span style="color:#66d9ef">PTR</span> [<span style="color:#66d9ef">rdx</span>]   <span style="color:#75715e">; load prevLayer.neurons[j].value
</span><span style="color:#75715e"></span><span style="color:#66d9ef">mulss</span>  <span style="color:#66d9ef">xmm0</span>, <span style="color:#66d9ef">DWORD</span> <span style="color:#66d9ef">PTR</span> [<span style="color:#66d9ef">rax</span>]   <span style="color:#75715e">; * currNeuron.weights[j]
</span><span style="color:#75715e"></span><span style="color:#66d9ef">add</span>    <span style="color:#66d9ef">rax</span>,  <span style="color:#ae81ff">4</span>                 <span style="color:#75715e">; next weight
</span><span style="color:#75715e"></span><span style="color:#66d9ef">add</span>    <span style="color:#66d9ef">rdx</span>,  <span style="color:#ae81ff">32</span>                <span style="color:#75715e">; next neuron (stride = 32 bytes)
</span><span style="color:#75715e"></span><span style="color:#66d9ef">addss</span>  <span style="color:#66d9ef">xmm1</span>, <span style="color:#66d9ef">xmm0</span>              <span style="color:#75715e">; accumulate z
</span></code></pre></div><p>Though it uses the same <code>xmm</code> registers, it does not use the full width. Instead of packing 4 floats at once (a 16-byte register can fit 4 floats), it loads a single weight and a single value. No vectorization here at all! Why does it do it like that? I don&rsquo;t know <code>¯\_(ツ)_/¯</code>.</p>
<p>Probably it uses some heuristics and thinks that packing 4 floats into a single register would be more expensive than packing 2 doubles. But I can say for sure that using the so-called <em>Array of Structures</em> (AoS), i.e., storing neurons in a vector, plays a bad game here. Because of the stride between two adjacent elements, the access pattern is broken.</p>
<p>If I were to use the <em>Structure of Arrays</em> (SoA), and store biases and values in dedicated vectors instead of a <code>Neuron</code> class, I&rsquo;m pretty sure the picture would be different - in this case, the access pattern would be straightforward and the compiler could fully utilize SIMD instructions.</p>
<p>Is it possible to fix that? Yes - as mentioned, replacing the <code>Neuron</code> class with something else would work. But I will not do it. Remember, this is a first-step naive implementation. In my next attempt, I&rsquo;ll use a highly optimized SIMD library for the math and even more. So stay tuned.</p>
<p>Sorry for the wasted traffic, but I&rsquo;ll share my favorite C++ memes, which I remember every time I get frustrated - like right now:</p>
<a href="#images%2f1.jpeg">
    <img src=images/1.jpeg class="thumbnail">
</a>
</br>
  

<a href="#_" class="lightbox" id="images/1.jpeg">
  <img src=images/1.jpeg>
</a>
<a href="#images%2f2.png">
    <img src=images/2.png class="thumbnail">
</a>
</br>
  

<a href="#_" class="lightbox" id="images/2.png">
  <img src=images/2.png>
</a>
<a href="#images%2f3.jpg">
    <img src=images/3.jpg class="thumbnail">
</a>
</br>
  

<a href="#_" class="lightbox" id="images/3.jpg">
  <img src=images/3.jpg>
</a>
<h2 id="conclusion">Conclusion</h2>
<p>This was a brief explanation of why <code>double</code>s can sometimes be faster than <code>float</code>s. If you spot any errors, please let me know. There&rsquo;s no code for this step.</p>
<p>I am using a static generator (<code>Hugo</code>) to build this site, so there is no comment section directly here. As a personal experiment, I published a short <a href="">post on LinkedIn</a> pointing to this article. If you have a question, you can ask it there. If you want to follow for updates, you can also <a href="https://www.linkedin.com/in/nikitablack">follow me</a> there.</p>

      
      <div class="related">
</div>
      
    </div>
    
  </div>
</section>



<section class="section">
  <div class="container has-text-centered">
    <p>If you like what I do you can <a href="https://www.buymeacoffee.com/nikitablack">buy me a coffee</a> &copy; <a href="http://nikitablack.github.io/">nikitablack</a> 2021</p>
    
      <p>Powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/ribice/kiss">Kiss</a>.</p>
    
  </div>
</section>



</body>
</html>

